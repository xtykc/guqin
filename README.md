# 古琴减字谱多模态大模型
本项目旨在通过一系列实验，探索如何通过数据集构建和训练一个古琴减字谱多模态大模型，实现古琴减字谱的识谱和释谱应用场景。
实验主要分为4个阶段：

## 阶段一：数据集构建
包括多模态资源采集和结构化数据清洗加工、古琴减字谱知识图谱构建、多模态大模型训练数据集构建。

## 阶段二：多模态大模型少样本微调
包括基座模型微调和对话模型微调，前者用于识谱，后者用于释谱。

### [基座模型微调](基座模型微调.md)

### [对话模型微调](对话模型微调.md)

 
## 阶段三：多模态大模型大样本微调和继续预训练

### [基座模型大样本微调](基座模型大样本微调.md)

### [对话模型继续预训练](对话模型继续预训练.md)

## 阶段四：基于知识图谱的检索增强生成（KG-RAG）

    为了能为用户提供更多元化和启示性的谱字解释在本地部署了经过继续与训练的对话模型，还同时部署了未经微调的MiniCPM-V(7.6b)、MiniCPM-V2.5(8b)、通义千问Qwen2.5(7b)、零一万物Yi(9b)、谷歌Gemma(7b)、Deepseek r1(7b)，Deepseek r1(8b)，都选择了10b以下小尺寸版本，其中Deepseek r1(7b)，Deepseek r1(8b)分别蒸馏自Qwen和Llama。
    
    为了比较RAG对不同模型能力的影响，在释谱界面上还提供了3种可选模式：KG-RAG，RAG，None-RAG。在KG-RAG的模式下，先经由基座模型识别出用户输入的谱字图像的谱字名称，再将谱字名称作为检索词，在古琴减字谱知识图谱中检索出与之相关的基础谱字名称及其说明，再将谱字名称、基础谱字名称及其说明，加上用户输入的指令，构造成复合提示词传给用户所选的大模型，生成输出，完成自然语言交互。
