# 对话模型微调

## 实验一：
数据集：《古琴传统指法举要》减字谱225个，图像225张，每个减字谱6轮对话，其中训练集和验证集的分配比例为8:2。
利用上述数据集，在学习率（learn rate, lr）超参设置为 1e-5、硬件环境为NVIDA 4090D 24G的情况下，微调训练总耗时为0.4个小时，共训练了100个轮次。
微调结果如下：
train_loss : 1.9419
根据streamlit前端演示界面的对话效果，发现经过微调训练后的模型仍然将减字谱认作普通的汉字。

## 实验二：
数据集：《古琴减字谱数据集成》减字谱13254个，图像13254张，图文比1:1，每个减字谱6轮对话共125万余字的数据集，其中训练集的数量为10000，验证集的数量为3254。
利用上述数据集，在学习率（learn rate, lr）超参设置为 1e-5、硬件环境为NVIDA 4090D 24G的情况下，微调训练总耗时为1.4个小时，共训练了10000个轮次。
微调结果如下：
train_loss : 1.1068
从损失函数的值来看，有大幅度的降低，但根据streamlit前端演示界面的对话效果，发现经过微调训练后的模型仍然无法正确地识别减字谱图像，经提示后仍然无法具备减字谱相关的基础知识。

## 实验三：
将阶段一构建的277个古琴减字谱的知识图谱作为训练数据集，以增强训练数据集的知识密度。基于知识图谱为每个减字谱生成22轮对话的指令数据，加入到训练数据集中进行训练，考察训练的效果以验证假设。利用基于知识图谱生成的训练数据集，在与实验一同样的学习率（learn rate, lr）超参设置和硬件环境的情况下，微调训练总耗时为4个小时，共训练了1000个轮次。
微调结果如下：
 train_loss : 1.1058 ↓
根据streamlit前端演示界面的对话效果，发现经过微调训练后的模型与实验一相比有较大的改善，一是可以识别减字谱图像为减字谱而非普通汉字，二是虽然无法准确识别整个减字谱，但可以正确地识别一个复合谱字中的某些部件，例如将“大四擘四”识别为“大四按七”。

277个古琴减字谱的知识图谱可视化效果如下：
 ![少样本数据集](https://github.com/xtykc/guqin/blob/main/%E5%8F%A4%E7%90%B4%E5%87%8F%E5%AD%97%E8%B0%B1%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1.png "277个谱字知识图谱")
