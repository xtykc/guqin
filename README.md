# 古琴减字谱多模态大模型
本项目旨在通过一系列实验，探索如何通过数据集构建和训练一个古琴减字谱多模态大模型，实现古琴减字谱的识谱和释谱应用场景。
实验主要分为3个阶段：

## 阶段一：数据集构建
包括多模态资源采集和结构化数据清洗加工、古琴减字谱知识图谱构建、多模态大模型训练数据集构建。

## 阶段二：多模态大模型少样本微调

### 基座模型微调
实验一：
数据集：96个减字谱谱字（96个古琴减字谱样本）的图文对照数据（约500张图像），平均每个谱字约对应5张图像，图（谱字图像）-文（谱字名称）比为5:1，其中训练集和验证集的分配比例为8:2。
利用上述数据集，在学习率（learn rate, lr）超参设置为 5e-6、批次大小（Batch Size）超参设置为12、训练的模态为Text和Vision、硬件环境为Apple pro M3 48G CPU的情况下，微调训练总耗时为1.445天个34.68小时，共训练了200个轮次，得到的模型为GuQin_IB-LoRA-200。
微调结果如下：
train loss epoch: 2.2171 
train loss cross epoch: 1.6736
val acc top 1: 0.5556
val acc top 5: 0.8681

实验二：
采用与实验一同样的实验方案，但将训练数据集增加到减字谱图像约4000张，平均每个减字谱约对应50张图像，图（谱字图像）-文（谱字名称）比为50:1，其中训练集和验证集的分配比例仍为8:2。基于该数据集，在与实验一同样的学习率（learn rate, lr）超参设置为 5e-6、批次大小（Batch Size）超参设置为12、训练的模态为Text和Vision、而将硬件环境升级为NVIDA 4090D 24G的情况下，微调训练总耗时为12个小时，共训练了180个轮次，得到的模型为GuQin_IB-LoRA-180。
微调结果如下：
train loss epoch: 1.5672 ↓
train loss cross epoch：0.6305 ↓
acc top 1: 0.7884 ↑
acc top 5: 0.9538 ↑
实验二表明，增加训练数据集的规模和改善硬件环境，可以显著优化各项微调训练的指标，降低损失函数的值，提升模型在验证数据集上的精确度。

实验三：
采用与实验二同样的实验方案，硬件环境和超参设置不变，训练数据集的图文配对数据规模和比例不变，但在训练数据集中增加与谱字相对应音频，每个减字谱对应一个音频，训练的模态为Text、Vision和Audio三个模态。继续在实验二的基础上，微调训练总耗时12.18小时，共训练了220个轮次，得到的模型为GuQin_IB-LoRA-220。
微调结果如下：
epoch loss : 1.5609 ↓
cross epoch loss：0.6304 ↓
acc top 1: 0.8042 ↑
acc top 5: 0.9666 ↑

96个古琴减字谱楷体字符样本如下：
![少样本数据集](https://github.com/xtykc/guqin/blob/main/%E5%8F%A4%E7%90%B4%E5%87%8F%E5%AD%97%E8%B0%B1%E5%86%85%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86-96.jpg "96个复合谱字")

### 对话模型微调
实验一：
数据集：《古琴传统指法举要》减字谱225个，图像225张，每个减字谱6轮对话，其中训练集和验证集的分配比例为8:2。
利用上述数据集，在学习率（learn rate, lr）超参设置为 1e-5、硬件环境为NVIDA 4090D 24G的情况下，微调训练总耗时为0.4个小时，共训练了100个轮次。
微调结果如下：
train_loss : 1.9419
根据streamlit前端演示界面的对话效果，发现经过微调训练后的模型仍然将减字谱认作普通的汉字。

实验二：
数据集：《古琴减字谱数据集成》减字谱13254个，图像13254张，图文比1:1，每个减字谱6轮对话共125万余字的数据集，其中训练集的数量为10000，验证集的数量为3254。
利用上述数据集，在学习率（learn rate, lr）超参设置为 1e-5、硬件环境为NVIDA 4090D 24G的情况下，微调训练总耗时为1.4个小时，共训练了10000个轮次。
微调结果如下：
train_loss : 1.1068
从损失函数的值来看，有大幅度的降低，但根据streamlit前端演示界面的对话效果，发现经过微调训练后的模型仍然无法正确地识别减字谱图像，经提示后仍然无法具备减字谱相关的基础知识。

实验三：
将阶段一构建的277个古琴减字谱的知识图谱作为训练数据集，以增强训练数据集的知识密度。基于知识图谱为每个减字谱生成22轮对话的指令数据，加入到训练数据集中进行训练，考察训练的效果以验证假设。利用基于知识图谱生成的训练数据集，在与实验一同样的学习率（learn rate, lr）超参设置和硬件环境的情况下，微调训练总耗时为4个小时，共训练了1000个轮次。
微调结果如下：
 train_loss : 1.1058 ↓
根据streamlit前端演示界面的对话效果，发现经过微调训练后的模型与实验一相比有较大的改善，一是可以识别减字谱图像为减字谱而非普通汉字，二是虽然无法准确识别整个减字谱，但可以正确地识别一个复合谱字中的某些部件，例如将“大四擘四”识别为“大四按七”。

277个古琴减字谱的知识图谱可视化效果如下：
 
## 阶段三：多模态大模型大样本微调和继续预训练
