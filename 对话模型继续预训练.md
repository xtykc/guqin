# 对话模型继续预训练

## 数据集
以1464个基础谱字为主，只辅以部分能涵盖所有基础谱字及构造方法的复合谱字。其中有302个基础谱字是复合谱字的常用构造部件，找出由这302个基础谱字构成的复合谱字共26416个。
图文比从1:1扩大到平均10:1以上，少量常用谱字超过100:1。最终在所有的基础谱字和复合谱字中过滤出有多张图像的谱字共18833个，谱字图像共195832张。

## 算力配备
GPU的从NVIDA 4090D 24G升级到H20-NVLink 96G。在训练方式上，采用全参数微调的方式。最终，基于上述训练数据集对总参数量为2.8B的MiniCPM-V2.0进行全参数微调，在学习率（learn rate, lr）超参设置为 1e-6、硬件环境为1张NVIDA H20-NVLink 96G的情况下，微调训练总耗时为9.6156小时，共训练了1200个轮次，得到古琴减字谱多模态对话模型“GuQin_MiniCPM-V2.0-LoRA1.2”。

## 训练结果
train_loss :1.4257
eval_loss: 1.5265
